\chapter{The derivative}

Before we begin dealing with derivative, we must build some of the tools needed to define it and evaluate its existence. We begin by evaluating limits on a function, which lead us to the cornerstone concept of continuity. 

\section{Continuity}

In order to expand our concepts of limits from sequences to functions on real numbers, we begin by defining the points on the real line we will be able to evaluate the future concepts.

\subsection{Limits of function}

\begin{definition}[Cluster point]
    Let $S \subseteq \R$. Then, $x \in \R$ is a cluster point of $S$ if $\forall \delta > 0, (x-\delta, x+ \delta) \cap S \setminus\{x\} \neq \varnothing$
\end{definition}

This notion can be further clarified by a few examples:
\paragraph{Examples}
\begin{enumerate}
    \item $S = \{1/n: n \in \N\}$: $0$ is a cluster point of $S$, since $1/n$ can be made arbitrary small, so $ (0 - \delta, 0 + \delta) \cap S \setminus \{0\} \neq \varnothing, \forall \delta > 0$.
    \item $S = (0,1)$ then $[0,1]$ is the set of cluster points of $S$.
    \item $S = \Q$ then $\R$ is the set of cluster points.
\end{enumerate}

\begin{theorem}
    Let $S \subseteq \R$, then $x$ is a cluster point of $S$ if, and only if, there exists a sequence $\{x_n\}$ of elements in $S \setminus \{x\}$ such that $x_n \to x$.
\end{theorem}

\begin{definition}[Function convergence]
    Consider $S \subseteq \R$, $c$ a cluster point of $S$, and $f: S \to \R$. Then, $f(x)$ converges to $L \in \R$ at $c$ if $\forall \varepsilon > 0, \exists \delta > 0$ such that if $x \in S$ and $0 < |x-c| < \delta$, then $|f(x) - L| < \varepsilon$. \\
    We can write $f(x) \to L$ as $x \to c$ or $\lim_{x \to c} f(x) = L$.
\end{definition}

\begin{theorem}[Uniqueness of the limit of a function]
    Let $c$ be a cluster point of $S \subseteq \R$ and $f: S \to \R$. If $f(x) \to L_1$ and $f(x) \to L_2$ as $x \to c$ then $L_1 = L_2$.
\end{theorem}

\begin{proof}
    Take $\varepsilon > 0$, since $f(x) \to L_1$ and $f(x) \to L_2, \exists \delta_1, \delta_2 \in \R$ such that if $x \in S$ with $0 < |x-c| < \delta_1$ and $0 < |x-c| < \delta_2$ we have $|f(x) - L_1| < \varepsilon/2$ and $|f(x) - L_2| < \varepsilon/2$. \\
    Choose $\delta = \min\{\delta_1, \delta_2\}$. Since $c$ is a cluster point of $S, \exists x_0 \in S$ such that $0 < |x_0-c| < \delta \longrightarrow |L_1-L_2| = |L_1 - f(x_0) + f(x_0) - L_2| \leq |L_1 - f(x_0)| + |f(x_0) - L_2| < \varepsilon$.
\end{proof}

\begin{theorem}
    Consider $c$ a cluster point in $S \subseteq \R$, and $f: S \to \R$. Then, the following statements are equivalent:
    \begin{itemize}
        \item $\lim_{x \to c} f(x) = L$ and,
        \item for every sequence $\{x_n\}$ in $S \setminus \{x\}$ such that $x_n \to c$, then $f(x_n) \to L$.
    \end{itemize}
\end{theorem}

\begin{proof}
    Proving each direction of the theorem individually:
    \begin{enumerate}
        \item Suppose $f(x) \to L$ as $x \to c$, then consider $\{x_n\}$ in $S \setminus \{x\}$ such that $x_n \to c$. Let $\varepsilon > 0, \exists \delta > 0$ such that $|f(x) - L| < \varepsilon$ if $x \in S$ and $0 < |x-c| < \delta$. Since $x_n \to c, \exists N \in \N$ such that $0 < |x_n-c| < \delta, \forall n \geq N$, since $|f(x) - L| \varepsilon, \forall 0 < |x-c| < \delta$ then $f(x_n) \to L$.
        \item Assuming the second part is false, for contradiction, $\exists \varepsilon_0 > 0$ such that $\forall \delta > 0, \exists x \in S$ such that $0 < |x-c| < \delta$ and $|f(x) - L| \geq \varepsilon_0$. Then, $\forall n \in \N, \exists x_n \in S$ such that $0 < |x_n - c| < 1/n$ and $|f(x_n) - L| \geq \varepsilon_0$. By the squeeze theorem we conclude $x_n \to c$ and $0 = \lim_{n \to \infty} |f(x_n) - L| \geq \varepsilon_0 > 0$ which is a contradiction.
    \end{enumerate}
\end{proof}

\begin{theorem}
    \begin{equation*}
        \lim \limits_{x \to 0} \sin (1/x) \textnormal { does not exist}
    \end{equation*}
\end{theorem}

\begin{proof}
    Let $x_n = \frac{2}{(2n-1)\pi}$. Then, $x_n \neq 0$ and $x_n \to 0$. Now,
    \begin{equation*}
        \sin (1/x_n) = \sin \frac{(2n-1) \pi}{2} = (-1)^{n+1}
    \end{equation*}
\end{proof}

\begin{theorem}
    \begin{equation*}
        \lim \limits_{x \to 0} x \sin(1/x) = 0
    \end{equation*}
\end{theorem}

\begin{proof}
    Suppose $x_n \neq 0$ and $x_n \to 0$. Then,
    \begin{equation*}
        0 \leq |x_n \sin(1/x_n)| = |x_n||\sin(1/x_n)| \leq |x_n|
    \end{equation*}
    By the squeeze theorem, $\lim _{n \to \infty} |x_n \sin(1/x_n)| = 0$
\end{proof}

\begin{theorem}
    Consider $c$ a cluster point in $S \subseteq \R$ and $f,g: S \to \R$, with $f(x) \leq g(x), \forall x \in S$. Suppose $\lim_{x \to c} f(x)$ and $\lim_{x \to c} g(x)$ both exist. Then,
    \begin{equation*}
        \lim \limits_{x \to c} f(x) \leq \lim \limits_{x \to c} g(x)
    \end{equation*}
\end{theorem}

\begin{proof}
    Define $L_1 = \lim_{x \to c} f(x)$ and $L_2 = \lim_{x \to c} g(x)$, and $\{x_n\}$ to be a sequence in $S \setminus \{c\}$ with $x_n \to c$. Then, $f(x_n) \leq g(x_n), \forall n \in \N$. So,
    \begin{equation*}
        L_1 = \lim \limits_{n \to \infty} f(x_n) \leq \lim \limits_{n \to \infty} g(x_n) = L_2
    \end{equation*}
\end{proof}

\begin{definition}[Convergence from the left]
    Consider $c$ to be a cluster point of $S \cap (-\infty, c)$ with $S \subseteq \R$. Then, we say $f(x)$ converges to $L$ from the left (or as $x \to c^-$) if $\forall \varepsilon > 0, \exists \delta >0$ such that if $x \in S$ and $c - \delta < x < c$ we obtain $|f(x) - L| < \varepsilon$. \\
    We denote it by $L = \lim_{x \to c^-} f(x)$.
\end{definition}

\begin{definition}[Convergence from the right]
    Consider $c$ to be a cluster point of $S \cap (c, \infty)$ with $S \subseteq \R$. Then, we say $f(x)$ converges to $L$ from the right (or as $x \to c^+$) if $\forall \varepsilon > 0, \exists \delta >0$ such that if $x \in S$ and $c < x < c + \delta$ we obtain $|f(x) - L| < \varepsilon$. \\
    We denote it by $L = \lim_{x \to c^+} f(x)$.
\end{definition}

\paragraph{Example} Consider
\begin{equation*}
    f(x) = \begin{cases}
    1 \textnormal{ if } x > 0 \\
    0 \textnormal{ if } x < 0
    \end{cases}
\end{equation*}
Then, $\lim_{x \to 0^-} f(x) = 0$ and $\lim_{x \to 0^+} f(x) = 0$, despite $f(0)$ being undefined.

\begin{theorem}
    Consider $c$ a cluster point of $S\cap(-\infty, c)$ and $S\cap(c, \infty)$, with $S \subseteq \R$. Then, $c$ is a cluster point of $S$. Or equivalently:
    \begin{equation*}
        \lim \limits_{x \to c} f(x) = L \longleftrightarrow \lim \limits_{x \to c^-} f(x)= \lim \limits_{x \to c^+} f(x) = L
    \end{equation*}
\end{theorem}

\subsection{Continuity of a function}

As shown in a past example, it is possible that $\lim_{x \to c} f(x) \neq f(c)$. In other words, it is possible that a limit of a function as $x \to c$ (or $x \to c^-$, $x \to c^+$) differs from $f(c)$. Continuity links the two concepts.

\begin{definition}[Continuous function]
    Consider $c \in S \subseteq \R$ a cluster point. We say $f$ is continuous at $c$ if $\forall \varepsilon > 0, \exists \delta > 0$ such that if $x \in S$ with $|x-c| < \delta$ then $|f(x)-f(c)| < \varepsilon$. If $f$ is continuous at all points of $U \subseteq S$ then $f$ is continuous on $U$.
\end{definition}

\begin{theorem}
    Consider $c \in S \subseteq \R$, and $f: S \to \R$, then:
    \begin{enumerate}
        \item if $c$ is not a cluster point of $f$, then $f$ is continuous at $c$,
        \item if $c$ is a cluster point of $f$, then $f$ is continuous at $c$ if, and only if, $\lim_{x \to c} f(x) = f(c)$,
        \item $f$ is continuous at $c$, and only if, for all sequence $\{x_n\}$ in $S$ with $x_n \to c$ then $f(x_n) \to f(c)$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Proving each statement:
    \begin{enumerate}
        \item Consider $\varepsilon > 0$, since $c$ is not a cluster point of $S$ then $\exists \delta >0$ such that $(c-\delta, c+ \delta) \cap S = \{c\}$, so if $x \in S$ and $|x-c| < \delta$ then $x = c$ and $|f(x) - f(c)| < \varepsilon$.
        \item Proving each direction of the statement:
            \begin{itemize}
                \item $(\Longleftarrow)$ If $\lim_{x \to c} f(x) = f(c)$ then $\forall \varepsilon > 0, \exists \delta > 0$ such that if $x \in S$ and $|x-c| < \delta$ then $|f(x) - f(c)| < \varepsilon$.
                \item $(\Longrightarrow)$ If $f$ is continuous at $c$ then $\forall \varepsilon > 0, \exists \delta > 0$ such that if $x \in S$ with $|x-c| < \delta$ then $|f(x) - f(c)| < \varepsilon$.
            \end{itemize}
        \item Proving each direction of the statement:
            \begin{itemize}
                \item $(\Longrightarrow)$, let $\{x_n\}$ in $S$ with $x_n \to c$. Take $\varepsilon > 0$, since $f$ is continuous at $c$, $\exists \delta > 0$ such that if $|x-c| < \delta$ with $x \in S$ then $|f(x_n) - f(c)| < \varepsilon$. Since $x_n \to c, \exists N \in \N$ such that $|x_n-c| <  \delta, \forall n \geq N$. So, $|x_n-c| < \delta \longrightarrow |f(x_n) - f(c)| < \varepsilon$.
                \item $(\Longleftarrow)$ For contradiction, assume $f$ is not continuous at $c$, then $\exists \varepsilon_0 > 0$ such that $\forall \delta > 0, \exists x \in S$ such $|x-c| < \delta$ and $|f(x) - f(c)| \geq \varepsilon_0$. Thus, $\forall n \in N, \exists x_n \in S$ such that $|x_n-c| < 1/n$ and $|f(x_n) -  f(c)| \geq \varepsilon_0$. Thus, by the squeeze theorem $|x_n - c| \to 0$ and $x_n \to c$ which implies $f(x_n) \to x$ which is a contradiction.
            \end{itemize}
    \end{enumerate}
\end{proof}

\begin{definition}[Bounded function]
    A function $f: S \to \R$ is bounded if $\exists M \geq 0$ such that $|f(x)| \leq M, \forall x \in S$.
\end{definition}

\begin{theorem}
    If $f: [a,b] \to \R$ is continuous at $[a,b]$ then it is bounded.
\end{theorem}

\begin{proof}
    For contradiction, assume $f$ is continuous but not bounded. Then, $\forall n \in \N, \exists x_n \in [a,b]$ such that $|f(x)| \geq n$. By the Bolzano-Weierstrass theorem, there exists a subsequence $\{x_{n_k}\}$ of $\{x_n\}$ with $x \in \R$ and $x_{n_k} \to x$. Since, $x_{n_k} \in [a,b], \forall k \in \N$ then $x \in [a,b]$. Given $f$ is continuous
    \begin{equation*}
        f(x) = \lim \limits_{k \to \infty} f(x_{n_k}) \Longrightarrow |f(x)| = \lim \limits_{k \to \infty} |f(x_{n_k})|
    \end{equation*}
    Hence, $\{|f(x_{n_k})\}$ is bounded and so is $\{n_k\}$ since $n_k \leq |f(x_{n_k})|$, from the definition of a subsequence $k \leq x_k, \forall k \in N$, contradicting the initial claim.
\end{proof}

\begin{theorem}[Min-max theorem or Extreme value theorem]
    Consider $f: [a,b] \to \R$. If $f$ is continuous on $[a,b]$ then it achieves an absolute maximum and absolute minimum on $[a,b]$.
\end{theorem}

\begin{proof}
    For the absolute maximum, if $f$ is continuous then $f$ is bounded. Thus, $E = \{ f(x): x \in [a,b]\}$ is bounded. Let $L = \sup E$ then,
    \begin{itemize}
        \item $L$ is an upper bound for $E$
        \item There exists a sequence $\{f(x_n)\}$ with $x_n \in [a,b]$ such that $f(x_n) \to L$
    \end{itemize}
    By the Bolzano-Weierstrass theorem, there exists a subsequence $\{x_{n_k}\}$ of $\{x_n\}$ and $d \in [a,b]$ such that $x_n \to d$ as $k \to \infty$. Hence,
    \begin{equation*}
        f(d) = \lim \limits_{k \to \infty} f(x_{n_k}) = \lim \limits_{n \to \infty} f(x_n) = L
    \end{equation*}
    by the continuity of $f$ on $[a,b]$. So, $f$ achieves an absolute maximum at $d$.
    The proof for the absolute minimum follows similarly.
\end{proof}

\begin{theorem}
    Consider $f: [a,b] \to \R$. If $f(a) < 0$ and $f(b) > 0$, then $\exists c \in (a,b)$ such that $f(c) = 0$
\end{theorem}

\begin{proof}
    Let $a_1 = a$ and $b_1 = b$. Define $a_n, b_n$ as follows:
    \begin{itemize}
        \item If $f((a_{n-1} + b_{n-1})/2) \geq 0$ then $a_n = a_{n-1}$ and $b_n = (a_{n-1} + b_{n-1})/2$,
        \item If $f((a_{n-1} + b_{n-1})/2 < 0$ then $a_n = (a_{n-1}+b_{n-1})/2$ and $b_n = b_{n-1}$.
    \end{itemize}
    In this way, we obtain:
    \begin{enumerate}
        \item $a \leq a_n \leq a_{n+1} \leq b_{n+1} \leq b_n \leq b, \forall n \in N$,
        \item $b_{n+1} - a_{n+1} = (b_n - a_n)/2, \forall n \in \N$,
        \item $f(a_n) \leq 0$ and $f(b_n) \geq 0, \forall n \in N$.
    \end{enumerate}
    From 1., $\{a_n\}$ and $\{b_n\}$ are bounded and monotone increasing and decreasing respectfully. Thus, $\exists c, d \in [a,b]$ such that $a_n \to c$ and $b_n \to d$. By 2.,
    \begin{equation*}
        b_n - a_n = \frac{b_{n-1} - a_{n-1}}{2} = \frac{1}{4}(b_{n-2} - a_{n-2}) = ... = \frac{1}{2^{n-1}}(b-a)
    \end{equation*}
    And,
    \begin{equation*}
        d - c = \lim \limits_{n \to \infty} (b_n - a_n) = \lim \limits_{n \to \infty} \frac{1}{2^{n-1}} (b-a) = 0 \Longrightarrow d = c
    \end{equation*}
    So, $a_n \to c$ and $b_n \to c$. By 3., $f(c) = \lim_{n \to \infty} f(a_n) \leq 0$ and $f(c) = \lim_{n \to  \infty} f(b_n) \geq 0$. Therefore, $f(c) = 0$.
\end{proof}

\begin{theorem}[Bolzano intermediate value theorem]
    Consider $f: [a,b] \to \R$ continuous. If $f(a) < f(b)$ with $y \in (f(a), f(b)), \exists c \in (a,b)$ such that $f(c) = y$. Else, if $ f(b) < f(a)$ with $y \in (f(b), f(a))$ then $\exists c \in (a,b)$ such that $f(c) = y$.
\end{theorem}

\begin{proof}
    Suppose $f(a) < f(b)$ with $y \in (f(a), f(b))$. Define $g(x) = f(x) - y$. Then, $f(x) = c \Longleftrightarrow g(x) = 0$ and $g: [a,b] \to \R$ is continuous, more importantly $g(a) = f(a) - y < 0$ and $g(b) = f(b) - y > 0$, then by the previous theorem $\exists c \in (a,b)$ such that $g(c) = y$ which is equivalent to $f(c) = y$. The proof for $f(b)<f(a)$ follows similarly.
\end{proof}

\begin{theorem}
    Consider $f: [a,b]  \to \R$ to be continuous. Take $c \in [a,b]$ to be where $f$ achieves a minimum value in $[a,b]$ and $d \in [a,b]$ to be where $f$ achieves a maximum value in $[a,b]$. Then, $f([a,b]) = [f(c), f(d)]$. Putting it in words: every value between the maximum and minimum is achieved.
\end{theorem}

\begin{proof}
    It is clear that $f([a,b]) \subseteq [f(c), f(d)]$. By the intermediate value theorem applied to $f: [c,d] \to \R$, we obtain $[f(c), f(d)] \subseteq f([c,d]) \subset f([a,b])$. Therefore, $f([a,b]) = [f(c), f(d)]$.
\end{proof}

\subsection{Uniform continuity}

\begin{definition}[Uniform continuity]
    Consider $f: S \to \R$. Then $f$ is continuous on $S$ if $\forall \varepsilon > 0, \exists \delta = \delta(\varepsilon) > 0$ such that $|x-c| < \delta$ implies $|f(x) - f(c)| < \varepsilon, \forall x \in S$.    
\end{definition}

\begin{theorem}
    Consider $f: [a,b] \to \R$, then $f$ is continuous if, and only if, $f$ is uniformly continuous.
\end{theorem}

\begin{proof}
    Proving each direction of the statement:
    \begin{itemize}
        \item $(\Longrightarrow)$: Suppose $f$ is continuous and assume for contradiction that $f$ is not uniformly continuous. Then, $\exists \varepsilon_0 > 0$ such that $\forall n \in \N, \exists x_n, c_n \in [a,b]$ such that $|x_n-c|<1/n$ and $|f(x_n) - f(c_n)| \geq \varepsilon_0$. \\
        By the Bolzano-Weierstrass theorem, there exists a subsequence $\{x_{n_k}\}$ of $\{x_n\}$ and $x \in [a,b]$ such that $x_{n_k} \to x$. Similarly, there also exists a subsequence $\{c_{n_k}\}$ of $\{c_n\}$ and $c \in [a,b]$ such that $c_{n_k} \to c$. And also, the subsequence $\{x_{n_{k_k}}\}$ of $\{x_{n_k}\}$ satisfies $x_{n_{k_j}} \to x$. Then, $|x-c| = \lim_{j \to \infty} |x_{n_{k_j}} - c_{n_{k_j}}| \leq \lim_{j \to \infty} 1/n_{k_j} - 0$. \\
        Thus, $x = c$. But since $f$ is continuous at $c$, $0 = |f(c) - f(c)| = \lim_{j \to \infty} |f(x_{n_{k_j}}) - f(c_{n_{k_j}})| \geq \varepsilon_0$ which is a contradiction to the initial claim.
    \end{itemize}
\end{proof}

\section{Differentiation}

\subsection{Definition and properties}

\begin{definition}[Derivative]
    Let $I$ be an interval with $f: I \to \R$ and $c \in I$. Then, $f$ is differentiable at $c$ if the limit
    \begin{equation}
        \lim \limits_{x \to c} \frac{f(x) - f(c)}{x-c}
    \end{equation}
    exists, in this case we write:
    \begin{equation}
        f'(c) = \lim \limits_{x \to c} \frac{f(x) - f(c)}{x-c}
    \end{equation}
    Furthermore, if $f$ is differentiable $\forall c \in I$ then we write the derivative as $f'$, or $f'(x)$ or $\frac{\dint f}{\dint x}$.
\end{definition}

\paragraph{Example} For all $n \in \N$, the derivative of the power function $f: \R \to \R$, $f(x) = \alpha x^n$ is given by $f'(c) = \alpha n c^{n-1}, \forall c \in \R$.

\begin{proof}
    First, note that $\forall n \in \N$:
    \begin{equation*}
        (x-c) \sum \limits_{j=0}^{n-1} x^{n-1-j}c^j = \sum \limits_{j=0}^{n-1}x^{n-j}c^j - \sum \limits_{j=0}^{n-1} x^{n-1-j}c^{j+1}
    \end{equation*}
    Defining $l = j + 1$:
    \begin{align*}
        (x-c) \sum \limits_{j=0}^{n-1} x^{n-1-j}c^j &= \sum \limits_{l=1}^{n}x^{n-j}c^j - \sum \limits_{j=0}^{n-1} x^{n-l}c^{l} \\
        &= x^{n-0}c^0 - x^{n-n}c^n \\
        &= x^n - c^n
    \end{align*}
    Therefore,
    \begin{equation*}
        f'(c) = \lim \limits_{x \to c} \frac{\alpha x^n - \alpha c^n}{x-c} = \alpha \lim \limits_{x \to c} \sum \limits_{j=0}^{n-1} x^{n-1-j}c^j = \alpha \sum \limits_{j=0}^{n-1} c^{n-1-j}c^j = \alpha n c^{n-1}
    \end{equation*}
\end{proof}

\begin{theorem}
    If the function $f: I \to \R$ is differentiable at $c \in I$, then it is also continuous at $c$.
\end{theorem}

\begin{proof}
    Since every point of $I$ is also a cluster point, then $f$ is continuous at $c \in I$ if, and only if, $\lim_{x \to c} f(x) = f(c)$. Now, 
    \begin{align*}
        \lim \limits_{x \to c} f(x) &= \lim \limits_{x \to c} (f(x) - f(c) + f(c)) \\
        &= \lim \limits_{x \to c} \left( (x-c)\frac{f(x)-f(c)}{x-c} + f(c)\right) \\
        &= 0 \cdot f'(c) + f(c) = f(c)
    \end{align*}
\end{proof}

\subsection{Weierstrass' function}

Continuity seems to be a prerequisite for the differentiation of a function. However, we may be tempted to take it as a sufficient condition, which unfortunately is not the case. This behaviour can be seen by an example.

\paragraph{Example} Consider $f(x) = |x|$. Then, $f$ is not differentiable at $0$, even though it is continuous at $0$.

\begin{proof}
    Consider a sequence $\{x_n\}$ such that $x_n \to 0$ and
    \begin{equation*}
        \lim \limits_{n \to \infty} \frac{f(x_n) - f(0)}{x_n - 0}
    \end{equation*}
    does not exist. Let $x_n = (-1)^n/n$. Then, $x_n \to 0$ and 
    \begin{equation*}
        \frac{f(x_n)-f(0)}{x_n - 0} = \frac{|(-1)^n/n|}{(-1)^n/n} =(-1)^n
    \end{equation*}
    Hence, $\lim_{n \to \infty} (-1)^n$ does not exist.
\end{proof}

It is clear that a function may be continuous, and yet non-differentiable at some point. However, if $f: \R \to \R$ is continuous at $\R$, is there a point $c \in \R$ such that $f$ is differentiable at $c$. The answer is no. There exists a function everywhere continuous and nowhere differentiable, called the Weierstrass' function.

In order to prove such function exists and fulfils the description above it is necessary to gather some tools, the following theorems are presented with this goal.

\begin{theorem}
    For the cosine function, it is true that:
    \begin{enumerate}
        \item $\forall x, y \in \R, |\cos x - \cos y| \leq |x - y|$
        \item For $c \in \R$ and $k \in \N$, $\exists y \in (c + \pi/k, c + 3\pi/k)$ such that $|\cos(kc) - \cos(ky)| \leq 1$.
    \end{enumerate}
\end{theorem}

\begin{theorem}
    For $a, b, c \in \R, |a + b + c| \leq |a| - |b| - |c|$.
\end{theorem}

\begin{proof}
    This follows from the triangle inequality:
    \begin{equation*}
        |a| = |a + b + c + (-b) + (-c)| \leq |a + b + c| + |b + c| \leq |a + b + c| + |b| + |c|
    \end{equation*}
\end{proof}

\begin{theorem}
    Consider the function:
    \begin{equation}
        f(x) = \sum \limits_{k = 0}^\infty \frac{\cos (160^k x)}{4^k}
    \end{equation}
    Then,
    \begin{enumerate}
        \item $\forall x \in \R, f(x)$ is absolutely convergent,
        \item $f(x)$ is bounded and continuous.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Proving each statement:
    \begin{enumerate}
        \item First, note that
            \begin{equation*}
                \left | \frac{\cos (160^k x)}{4^k}\right | \leq 4^{-k}, \forall k \in \N
            \end{equation*}
            Hence, the the comparison test, 
            \begin{equation*}
                \sum \limits_{k=0}^\infty \left | \frac{\cos (160^k x)}{4^k}\right |
            \end{equation*}
            converges.
        \item We begin by noticing:
        \begin{equation*}
            |f(x)| \leq \sum \limits_{k=0}^\infty \frac{|\cos (160^k)|}{4^k} \leq \sum \limits_{k=0}^\infty \frac{1}{4^k} = \frac{4}{3}
        \end{equation*}
        Hence, $f$ is bounded.\\
        Next, suppose $c \in \R$ and $x_n \to c$. Note that $\{|f(x_n) - f(c)|\}$ is bounded. Thus,
        \begin{equation*}
            \lim \limits_{n \to \infty} |f(x_n) - f(c)| = 0 \Longleftrightarrow \limsup \limits_{n \to \infty} |f(x_n) - f(c)| = 0
        \end{equation*}
        It is necessary to show $\limsup_{n \to \infty} |f(x_n) - f(c)| \leq \varepsilon, \forall \varepsilon > 0$. Choose $N_0 \in \N$ such that $\sum_{k=N_0 + 1}^\infty 4^{-k} < \varepsilon/2$. Then,
        \begin{align*}
            &\limsup \limits_{n \to \infty} |f(x_n) - f(c)| \\
            &= \limsup \limits_{n \to \infty} \left |
                \sum \limits_{k=0}^{N_0} \frac{\cos (160^k x_n)}{4^k} - \frac{\cos (160^k c)}{4^k} + 
                \sum \limits_{k=N_0 + 1}^\infty \frac{\cos (160^k x_n)}{4^k} - \frac{\cos (160^k c)}{4^k}
            \right | \\
            &\leq \limsup \limits_{n \to \infty} \sum \limits_{k = 0}^{N_0} 4^{-k} |\cos (160^k x) - \cos( 160^k c) + \sum \limits_{k = N_0 + 1}^\infty 4^{-k} |\cos (160^k x) - \cos( 160^k c) \\
            &\leq \limsup \limits_{n \to \infty} \left ( \sum \limits_{k=0}^{N_0} 4^{-k} \right ) |x_n - c| + \varepsilon = \varepsilon
        \end{align*}
    \end{enumerate}
\end{proof}

\begin{theorem}[Weierstrass function]
    The function:
    \begin{equation}
        f(x) = \sum \limits_{k = 0}^\infty \frac{\cos(160^k x)}{4^k}
    \end{equation}
    is nowhere differentiable.
\end{theorem}

\begin{proof}
    Consider $c \in \R$, our goal is to find a sequence $\{x_n\}$ with $x_n \to c$ such that
    \begin{equation*}
        \left \{
            \frac{f(x_n) - f(c)}{x_n - c}
        \right \}
    \end{equation*}
    is unbounded. From one of the previous theorem, $\forall n \in \N, \exists x_n$ such that $\pi/160^n < x_n - c < 3\pi/160^n$ and $|\cos (160^n c) - \cos (160^n x_n)| \geq 1$. So, $x_n \neq 0, \forall n \in \N$ and $|x_n - c| \leq 3 \pi/160^n \to 0$. Define:
    \begin{equation*}
        f_k(x) = \frac{\cos (160^k x)}{4^k}
    \end{equation*}
    So, $f(x) = \sum f_k(x)$. Thus, define:
    \begin{align*}
        f(c) - f(x_n) &= f_n(c) - f_n(x_n) + \sum \limits_{k=0}^{n-1}(f_k(c) - f_k(x_n)) + \sum \limits_{k=n}^\infty(f_k(c) - f_k(x_n)) \\
        &= a_n + b_n + c_n
    \end{align*}
    Then, $|a_n| = 4^{-n} |\cos (160^k x_n) - \cos (160^k c)| \geq 4^{-n}$. And,
    \begin{align*}
        |b_n| &\leq \sum \limits_{k=0}^{n-1} 4^{-k}|\cos (160^k c) - \cos (160^k x_n)|) \\
        &\leq \sum \limits_{k=0}^{n-1}4^{-k} 160^k |x_n - c| \\ 
        &\leq \frac{3 \pi}{160^n} \sum \limits_{k=0}^{n-1}40^k \\
        &= \frac{3 \pi}{160^n} \frac{40^n - 1}{39} \leq \frac{4^{-n+1}}{13}
    \end{align*}
    And,
    \begin{align*}
        |c_n| &\leq \sum \limits_{k = n+1}^\infty 4^{-k}(|\cos(160^k c)| + |\cos (160^k x_n)|) \\
        &\leq 2 \sum \limits_{k = n+1}^\infty 4^{-k} \\
        &= 2\cdot 4^{-n+1}\frac{4}{3} = 4^{-n} \frac{2}{3}
    \end{align*}
    Combining the former inequalities, we obtain:
    \begin{equation*}
        |f(c) - f(x_n)| \geq 4^{-n} \left(1 - \frac{4}{13} - \frac{2}{3} \right) = 4^{-n}\frac{1}{39}
    \end{equation*}
    Therefore,
    \begin{equation*}
        \frac{|f(c) - f(x_n)|}{|c-x_n|} \geq \frac{160^n}{3\pi} 4^{-n}\frac{1}{39} = \frac{40^n}{117 \pi}
    \end{equation*}
    Thus, the sequence is unbound and therefore does not converge for any $x \in \R$ and the derivative does not exist.
\end{proof}

\subsection{Differentiation rules and theorems}

\begin{theorem}[Chain rule]
    Consider $f: A \to B$ and $g: B \to \R$, with $f$ differentiable at $c \in A$ and $g$ differentiable at $f(c) \in B$. Then, $(g \circ f)'(c) = g'(f(c))f'(c)$.
\end{theorem}

\begin{proof}
    Let $h(x) = (g \circ f)(x)$ and $d = f(c)$. Define:
    \begin{equation*}
        u(y) = \begin{cases}
            \frac{g(y) - g(d)}{y - d} \text{ if } y \neq d \\
            g'(d) \: \: \: \: \: \: \text{ if } y = d
        \end{cases}
    \end{equation*}
    and,
    \begin{equation*}
        v(x) = \begin{cases}
            \frac{f(x) - f(c)}{x - c} \text{ if } x \neq c \\
            f'(c) \: \: \: \: \: \: \text{ if } x = c
        \end{cases}
    \end{equation*}
    Then,
    \begin{equation*}
        \lim \limits_{y \to d} u(y) = \lim \limits_{y \to d} \frac{g(y) - g(d)}{y - d} = g'(d) = u(d)
    \end{equation*}
    and,
    \begin{equation*}
        \lim \limits_{x \to c} v(x) = \lim \limits_{x \to c} \frac{f(x) - f(c)}{x - c} = d'(c) = v(c)
    \end{equation*}
    Which shows $u(y)$ and $v(x)$ are continuous. Now, $g(y) - g(d) = u(y)(y-d)$ and $f(x) - f(c) = v(x)(x-c)$. Then, $h(x) - h(c) = g(f(x)) - g(f(c)) = g(f(x)) - g(d) = u(f(x))(f(x) - f(c)) = u(f(x))v(x)(x-c)$. So, 
    \begin{align*}
        \lim \limits_{x \to c} \frac{h(x) - h(c)}{x - c} &= \lim \limits_{x \to c} u(f(x))v(x) \\
        &= u(f(c))v(c) \\
        &= f'(g(c))g'(c)
    \end{align*}
\end{proof}

\begin{theorem}
    Consider $f: I \to \R$ and $g: I \to \R$, both differentiable at $c \in I$. Then,
    \begin{enumerate}
        \item $(\alpha f)'(c) = \alpha f'(c), \forall \alpha \in \R$,
        \item $(f + g)'(c) = f'(c) + g'(c)$,
        \item $(fg)'(c) = f'(c)g(c) + f(c)g'(c)$,
        \item $(f/g)'(c) = \frac{f'(c)g(c) - f(c)g'(c)}{[g(c)]^2}$, provided $g(c) \neq 0$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Proving each statement:
    \begin{enumerate}
        \item This result follows directly from the definition:
            \begin{equation*}
                (\alpha f)'(c) = \lim \limits_{x \to c} \frac{(\alpha f)(x) - (\alpha f)(c)}{x - c} = \alpha \frac{f(x) - f(c)}{x-c} = \alpha f'(c)
            \end{equation*}
        Considering the algebraic properties of limits.
        \item Again, from the definition:
            \begin{align*}
                (f + g)'(c) &= \lim \limits_{x \to c}\frac{(f + g)(x) - (f + g)(c)}{x - c} = \lim \limits_{x \to c} \frac{f(x) - f(c)}{x-c} + \lim \limits_{x \to c}\frac{g(x) - g(c)}{x-c} \\
                &= f'(c)+g'(c)
            \end{align*}
        \item First, note:
            \begin{equation*}
                \frac{f(x)g(x) - f(c)g(c)}{x - c} = \frac{f(x) - f(c)}{x- c}g(x) + f(c) \frac{g(x) - g(c)}{x - c}
            \end{equation*}
            Then, taking $\lim_{x \to c}$, we obtain: $ (fg)'(c) = f'(c)g(c) + f(c)g'(c)$.
        \item Consider $h(x) = 1/g(x)$. By the chain rule $h'(c) = -g'(c)/[g(c)]^2$. Then, 
        \begin{align*}
            (f/g)'(c) &= (fh)'(c) = f'(c)h(c) + f(c)h'(c) = [f'(c)/g(c) - f(c)[g(c)]^2/g'(c)] \\
            &= [f'(c)g(c) - f(c)g'(c)]/[g(c)]^2   
        \end{align*}
        
    \end{enumerate}
\end{proof}

\begin{theorem}
    Consider $f: [a,b] \to \R$ to be a bijective function, and define $f^{-1}$, the inverse function such that $f^{-1}(y) = x$. If $f(x)$ is differentiable on $[a,b]$ and $f(x) \neq 0, \forall x \in [a,b]$ then:
    \begin{equation*}
        (f^{-1})'(y) = \frac{1}{f'(x)} \text{ where } y = f(x)
    \end{equation*}
\end{theorem}

\begin{proof}
    Since $f^{-1}(y) = x$ then $y = f(x)$. Taking the derivative with respect to $y$ on both sides:
    \begin{equation*}
        1 = f'(x) \frac{\dint x}{\dint y}
    \end{equation*}
    Thus,
    \begin{equation*}
        \frac{\dint x}{\dint y} = \frac{1}{f'(x)}
    \end{equation*}
    But $x = f^{-1}(y)$, so:
    \begin{equation*}
        (f^{-1})'(y) = \frac{1}{f'(x)}
    \end{equation*}
\end{proof}

\subsection{Mean value theorem}

\begin{definition}[Relative maximum/minimum]
    Consider $S \subseteq \R$ and $f: S \to \R$. Then, $f$ has a relative maximum at $c \in S$ if $\exists \delta > 0$ such that $\forall x \in S: |x-c| < \delta$ then $f(x) \leq f(c)$. The definition of minimum follows analogously.
\end{definition}

\begin{theorem}
    If $f:[a,b] \to \R$, $f$ has a relative min or max at $c \in (a,b)$ and $f$ is differentiable at $c$, then: $f'(c) = 0$.
\end{theorem}

\begin{proof}
    If $f$ has a relative maximum at $c \in (a,b)$, then $\exists \delta > 0$ such that $f(c) \leq f(x), \forall x in (c- \delta, c + \delta)$, with $x \in [a,b]$. Let 
    \begin{equation*}
        x_n = c - \frac{\delta}{2n} \in (c- \delta, c)
    \end{equation*}
    Then, $x_n \to c$, so:
    \begin{equation*}
        f'(c) = \lim \limits_{n \to \infty} \frac{f(x_n) - f(c)}{x_n - c} \geq 0
    \end{equation*}
    Now, define:
    \begin{equation*}
        y_n = c + \frac{\delta}{2n} \in (c, c+\delta)
    \end{equation*}
    Then, $y_n \to c$, and
    \begin{equation*}
        f'(c) = \lim \limits_{n \to \infty}\frac{(f(y_n) - f(c))}{y_n - c} \leq 0
    \end{equation*}
    Therefore, $f'(c) = 0$.
\end{proof}

\begin{theorem}[Rolle's theorem]
    Consider $f: [a,b] \to \R$ and $f$ differentiable in $(a,b)$, additionally if $f(a) = f(b)$, then $\exists c \in (a,b)$ such that $f'(c) = 0$.
\end{theorem}

\begin{proof}
    Let $Y = f(a) = f(b)$. Since $f$ is continuous $\exists c_1, c_2 \in [a,b]$ to be a relative maximum and a relative minimum, respectfully. Then if $f(c_1) > Y$ then $ c_1 \in (a,b)$ and $f'(c_1) = 0$. Similarly, if $f(c_2) < Y$ then $c_2 \in (a,b)$ and $f'(c_2) = 0$. If $f(c_1) \leq Y \leq f(c_2)$ then $f(x) = Y, \forall x \in [a,b]$, so $f'(c) - 0$ for any $c \in (a,b)$.
\end{proof}

\begin{theorem}[Mean value theorem]
    Consider $f: [a,b] \to \R$ to be continuous and differentiable in $(a,b)$. Then, $\exists c \in (a,b)$ such that $f(b) - f(a) = f'(c)(b - a)$.
\end{theorem}

\begin{proof}
    Define
    \begin{equation*}
        g(x) = f(x) - f(b) + \frac{f(b) - f(a)}{b - a}(b - x)
    \end{equation*}
    Then, $g(a) = g(b) = 0$. Thus, by the Rolle's theorem, $\exists c \in (a,b)$ such that $g'(c) = 0$. Hence,
    \begin{equation*}
        g'(c) = 0 = f'(c) - \frac{f(b) - f(a)}{b-a}
    \end{equation*}
\end{proof}

\begin{corollary}
    If $f: [a,b] \to \R$ is differentiable on $[a,b]$ and $f'(x) = 0, \forall x \in (a,b)$ then $f(x) = K$ for some constant $K \in \R$.
\end{corollary}

\begin{proof}
    Take $x_1, x_2 \in [a,b]$ and assume $x_1 < x_2$. Applying the Mean value theorem on $[x_1, x_2]$:
    \begin{equation*}
        f'(c) = \frac{f(x_2) - f(x_1)}{x_2 - x_1}
    \end{equation*}
    for some $c \in [x_1, x_2]$. On the other hand $f'(x) = 0 \forall x \in [a,b]$, so $f'(c) = 0$ which  implies $f(x_2) = f(x_1)$. Define $K = f(x_1) = f(x_2)$. Since $x_1, x_2$ are arbitrary, $f(x) = K, \forall x \in [a,b]$.
\end{proof}

\begin{corollary}
    If $f: S_1 \to \R$ and $g: S_2 \to \R$ are differentiable on $[a,b] \subseteq S_1 \cup S_2$ and $f'(x) = g'(x), \forall x \in [a,b]$ then $f(x) = g(x) + K$ with $K \in \R$ constant.
\end{corollary}

\begin{proof}
    Define $h(x) = f(x) - g(x)$. Then $h'(x) = f'(x) - g'(x) = 0 \forall x \in [a,b]$. So, from the previous theorem $h(x) = K$ which implies $f(x) = g(x) + K$.
\end{proof}

\begin{theorem}
    If $f: I \to \R$ is differentiable and $f'(x) = 0, \forall x \in I$ then $f$ is constant.
\end{theorem}

\begin{proof}
    Let $a,b \in I$ with $a < b$. Then, $f$ is continuous on $[a,b]$ and differentiable on $(a,b)$. So, by the previous theorem, $\exists c \in (a,b)$ such that $f(b) - f(a) = (b-a)f'(c) = 0$. Hence, $f(b) = f(a), \forall a, b \in I$ such that $a < b$.
\end{proof}

\begin{theorem}
    Consider $f: I \to \R$ differentiable, then:
    \begin{enumerate}
        \item $f$ is increasing if, and only if, $f'(x) \geq 0, \forall x \in I$, and
        \item $f$ is decreasing if, and only if, $f'(x) \leq 0, \forall x \in I$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Proving $f$ is increasing if $f'(x) \geq 0$.
    \begin{itemize}
        \item $(\Longleftarrow)$: Suppose $f'(x) \geq 0, \forall x \in I$. Then, let $a,b \in I$ with $a < b$. By the mean value theorem, $\exists c \in (a,b)$ such that $f(b) - f(a) = (b-a)f'(c) \geq 0 \Longrightarrow f(a) \leq f(b)$.
        \item $(\Longrightarrow)$: Suppose $f$ is increasing. Let $c \in $ and $\{x_n\}$ be a sequence in $I$ such that $x_n \to c$, with $x_n < c, \forall n \in \N$. Then, $f(x_n) - f(c) \leq 0, \forall n \in N$, and by consequence:
            \begin{equation*}
                f'(c) = \lim \limits_{n \to \infty} \frac{f(x_n) - f(c)}{x_n - c} \geq 0
            \end{equation*}
            On the other hand, if $\{x_n\}$ is such that $x_n \to c$ and $x_n > c, \forall n \in \N$ then: $f(x_n) - f(c) \geq 0, \forall n \in \N$, and:
            \begin{equation*}
                f'(c) = \lim \limits_{n \to \infty} \frac{f(x_n) - f(c)}{x_n - c} \geq 0
            \end{equation*}
            In either case, $f'(c) \geq 0$.
    \end{itemize}
    The proof for the decreasing function follows from taking $-f$ increasing, which is equivalent to $f$ decreasing.
\end{proof}

\begin{theorem}[Generalised mean value theorem]
    If $f: S_1 \to \R$ and $g: S_2 \to \R$ are continuous on $[a,b] \subseteq S_1 \cap S_2$ and differentiable on $(a,b)$ then, there exists a point $c \in (a,b)$ such that:
    \begin{equation*}
        [f(b) - f(a)]g'(c) = [g(b) - g(a)]f'(c)
    \end{equation*}
    If $g'(c) \neq 0, \forall c \in (a,b)$ then:
    \begin{equation*}
        \frac{f'(c)}{g'(c)} = \frac{f(b) - f(a)}{g(b) - g(a)}
    \end{equation*}
\end{theorem}

\begin{proof}
    Consider $h(x) = [f(b) - f(a)]g(x) - [g(b) - g(a)]f(x)$, then from the Mean value theorem $\exists c \in (a,b)$ such that:
    \begin{equation*}
        h'(c) = \frac{h(b) - h(a)}{b-a}
    \end{equation*}
    From the definition of $h(x)$, substituting $h(a)$ and $h(b)$:
    \begin{align*}
        h'(c) &= \frac{[f(b) - f(a)]g(b) - [g(b) - g(a)]f(b) - [f(b) - f(a)]g(a) + [g(b) - g(a)]f(a)}{b-a} \\
        &= \frac{f(b)g(b) - f(a)g(b) - g(b)f(b) + g(a)f(b) - f(b)g(a) + f(a)g(a) + g(b)f(a) - g(a)f(a)}{b-a} \\
        &= \frac{0}{b-a} \\
        &= 0
    \end{align*}
    On the other hand,
    \begin{equation*}
        h'(c) = [f(b) - f(a)]g'(c) - [g(b) - g(a)]f'(c)
    \end{equation*}
    So,
    \begin{equation*}
        [f(b) - f(a)]g'(c) = [g(b) - g(a)]f'(c)
    \end{equation*}
    If $g'(c) \neq 0, \forall c \in (a,b)$ then:
    \begin{equation*}
        \frac{f'(c)}{g'(c)} = \frac{f(b) - f(a)}{g(b) - g(a)}
    \end{equation*}
\end{proof}

\begin{definition}[Higher-order derivatives]
    Consider $f: I \to \R$. Then, $f$ is $n$ times differentiable on $J \subseteq I$ if $f'$, $f''$, ..., $f^{(n)}$ exist at every point of $J$. The $n$-th derivative of $f$ is denoted by $f^{(n)}$.
\end{definition}

\begin{theorem}[Second derivative test]
    Suppose $f: (a,b) \to \R$ has two continuous derivatives. If $x_0 \in (a,b)$ is such that $f'(x_0) = 0$ then:
    \begin{itemize}
        \item If $f''(x_0) > 0$, then $f$ has a relative minimum at $x_0$,
        \item If $f''(x_0) < 0$, then $f$ has a relative maximum at $x_0$,
        \item If $f''(x_0) = 0$, then $f$ is an inflection point.
    \end{itemize}
\end{theorem}

\begin{proof}
    Proving only the first result: if $f''$ is continuous at $x_0$ and $\lim_{c \to x_0} f''(c) = f''(x_0) > 0$. Then, $\exists \delta > 0$ such that $f''(c) > 0, \forall c \in (x_0 - \delta, x_0 + \delta)$. Take $ x \in (x_0 - \delta, x_0 + \delta)$, then, by Taylor's theorem, $\exists c \in (x, x_0)$ and $c \in (x_0 - \delta, x_0 + \delta)$ by consequence, such that:
    \begin{equation*}
        f(x) = f(x_0) + \frac{f''(c)}{2}(x-x_0)^2 \geq f(x_0)
    \end{equation*}
    With $f(x) > f(x_0)$ if $x \neq x_0$.
\end{proof}

\subsection{L'Hospital's Rules}

From the algebraic limit theorem,

\begin{equation*}
    \lim \limits_{x \to c} \frac{f(x)}{g(x)} = \frac{\lim \limits_{x \to c} f(x)}{\lim \limits_{x \to c} g(x)}
\end{equation*}

provided $\lim_{x \to c} g(x) \neq 0$. It is not difficult to argue that if the numerator tends to any number different from zero, while the denominator tends to zero the quotient explodes to infinity (positive or negative). However, there may be cases where both the numerator and denominator tend to zero, or alternatively where both terms tend to infinity. L'Hospital's rules provide an important tool for dealing with these cases.

\begin{theorem}[L'Hospital's rule: $0/0$ case]
    Consider $f: S_1 \to \R$ and $g: S_2 \to \R$ continuous with both functions differentiable on $A \subseteq S_1 \cap S_2$ with the possible exception of $a \in A$. If $f(a) = g(a) = 0$ and $g'(x) \neq 0, \forall x \neq a$, then:
    \begin{equation*}
        \lim \limits_{x \to a} \frac{f(x)}{g(x)} = \lim \limits_{x \to a} \frac{f'(x)}{g'(x)} =  L
    \end{equation*}
    provided $\lim_{x \to a} f'(x)/g'(x)$ exists. 
\end{theorem}

\begin{proof}
    From the Generalized mean value theorem:
    \begin{equation*}
        \frac{f'(c)}{g'(c)} = \frac{f(b) - f(a)}{g(b) - g(a)}
    \end{equation*}
    Taking the limit of $b \to a$ we have:
    \begin{enumerate}
        \item Since $c \in (a,b)$ then $a < c < b$. So, $a - b < c - b < 0$. $a - b \to 0$ as $ b \to a$. From the Squeeze theorem, $c \to b$ as $b \to a$. So, for the left-hand side of the Generalized mean value theorem stated above:
            \begin{equation*}
                \frac{f'(b)}{g'(b)}
            \end{equation*}
        \item For the right-hand side, since $f(a) = f(b) = 0$:
            \begin{equation*}
                \frac{f(b)}{g(b)}
            \end{equation*}
    \end{enumerate}
    So, 
    \begin{equation*}
        \lim \limits_{b \to a} \frac{f'(b)}{g'(b)} = \lim \limits_{b \to a} \frac{f(b)}{g(b)}
    \end{equation*}
\end{proof}

\begin{definition}
    Given a function $f: A \to \R$ and a point $a \in A$, then we denote $\lim_{x \to a} f(x) = +\infty$ if $\forall N > 0, \exists \delta > 0$ such that $f(x) > N, \forall x \in (a - \delta, a + \delta)$.
    Similarly, we can define $\lim_{x \to a} = - \infty$.
\end{definition}

\begin{theorem}[L'Hospital's rule: $\infty/\infty$ case]
    Consider $f: S_1 \to \R$ and $g: S_2 \to \R$ to be differentiable on $(a,b) \in S_1 \cap S_2$. If $g'(x) \neq 0, \forall x \in (a,b)$, $\lim_{x \to c} f(x)= \infty$ or ($-\infty$) and $\lim_{x \to c} g(x) = \infty$ or ($-\infty$), for $c \in (a,b)$, then:
    \begin{equation*}
        \lim \limits_{x \to c} \frac{f(x)}{g(x)} = \lim \limits_{x \to c} \frac{f'(x)}{g'(x)} = L
    \end{equation*}
    provided $\lim_{x \to c} f'(x)/g'(x)$ exist.
\end{theorem}

\begin{proof}
    Let $\varepsilon > 0$, since $\lim_{x \to c} f'(x)/g'(x) = L$, there exists $\delta_1$ such that:
    \begin{equation*}
        \left |
            \frac{f'(x)}{g'(x)} - L
        \right | < \frac{\varepsilon}{2}, \forall x \in (c-\delta_1, c+\delta_1)
    \end{equation*}
    Applying the Generalized mean theorem for $[x, c + \delta_1]$:
    \begin{equation*}
        \frac{f(c + \delta_1) - f(x)}{g(c + \delta_1) - g(x)} = \frac{f'(d)}{g'(d)}
    \end{equation*}
    for $d \in (x, c + \delta_1)$. So,
    \begin{equation*}
        L -  \frac{\varepsilon}{2} < \frac{f(c + \delta_1) - f(x)}{g(c + \delta_1) - g(x)} < L + \frac{\varepsilon}{2}, \forall x \in (c, c+\delta_1)
    \end{equation*}
    In order to isolate $f(x)/g(x)$ in the previous equation it is necessary to multiply the inequality by $(g(c+\delta_1) - g(x))/g(x)$. However, first this last term must be show to be strictly positive. We begin by noticing,
    \begin{equation*}
        \frac{g(c+\delta_1) - g(x)}{g(x)} = \frac{g(c+\delta_1)}{g(x)} - \frac{g(x)}{g(x)} > 0 \Longrightarrow \frac{g(c+\delta_1)}{g(x)} > 1
    \end{equation*}
    So, it is necessary $x$ such that $g(c + \delta_1) > g(x)$. Define $\delta_2$ such that $g(c + \delta_1) > g(x), \forall x \in (c, c+\delta_2)$. We obtain:
    \begin{equation*}
        \left( L - \frac{\varepsilon}{2} \right)
        \left( \frac{g(c+\delta_1)}{g(x)} - 1 \right)
        <
        \frac{f(c+\delta_1) - f(x)}{g(x)}
        <
        \left( L + \frac{\varepsilon}{2} \right)
        \left( \frac{g(c+\delta_1)}{g(x)} - 1 \right)
    \end{equation*}
    which leads to:
    \begin{equation*}
        L\frac{g(c+\delta_1)}{g(x)} - \frac{\varepsilon}{2}\frac{g(c+\delta_1)}{g(x)}
        - L + \frac{\varepsilon}{2}
        <
        \frac{f(c+\delta_1) - f(x)}{g(x)}
        <
        L\frac{g(c+\delta_1)}{g(x)} + \frac{\varepsilon}{2}\frac{g(c+\delta_1)}{g(x)}
        - L - \frac{\varepsilon}{2}
    \end{equation*}
    \begin{equation*}
        L + \frac{\varepsilon}{2} - \frac{Lg(c+\delta_1) + \frac{\varepsilon}{2} - f(c+\delta_1)}{g(x)}
        <
        \frac{f(x)}{g(x)}
        <
        L - \frac{\varepsilon}{2} - \frac{Lg(c+\delta_1) - \frac{\varepsilon}{2} - f(c+\delta_1)}{g(x)}
    \end{equation*}
    Define $\delta_3$ such that:
    \begin{equation*}
        \frac{Lg(c+\delta_1) + \frac{\varepsilon}{2} - f(c+\delta_1)}{g(x)} < \varepsilon
    \end{equation*}
    And
    \begin{equation*}
        \frac{Lg(c+\delta_1) - \frac{\varepsilon}{2} - f(c+\delta_1)}{g(x)} < \varepsilon
    \end{equation*}
    for all $x \in (c, c+ \delta_3)$. Then, for $\delta = \min \{ \delta_1, \delta_2, \delta_3 \}$,
    \begin{equation*}
        \left |
            \frac{f(x)}{g(x)} - L
        \right | < \varepsilon
    \end{equation*}
\end{proof}

\subsection{Smoothness Classes}

\begin{definition}[Smoothness classes]
    Consider $f: S \to \R$ and $k$ a non-negative integer. If the function $f$ is $k$-th order differentiable with $f^{(k)}(x)$ continuous on $S$, then $f$ is of class $\mathcal{C}^k(S)$. \\
    If $f$ is infinitely differentiable with all derivatives continuous on $S$, then $f$ is called smooth, and belongs to the class $\mathcal{C}^\infty(S)$.
\end{definition}

\begin{remark}
    A continuous function belongs to the class $\mathcal{C}^0$.
\end{remark}

Each class $\mathcal{C}^r(S)$ can be understood as a ``set of functions of class $\mathcal{C}^r(S)$''. In this way,

\begin{equation*}
    \mathcal{C}^\infty(S) = \bigcap \limits_{r \in \N} \mathcal{C}^r(S) \subseteq \cdot \cdot \cdot \subseteq \mathcal{C}^1(S) \subseteq \mathcal{C}^0(S)
\end{equation*}

Where each inclusion $\mathcal{C}^i(S) \subseteq \mathcal{C}^{i-1}(S)$ is proper.