\chapter{The derivative}

Before we begin dealing with derivative, we must build some of the tools needed to define it and evaluate its existence. We begin by evaluating limits on a function, which lead us to the cornerstone concept of continuity. 

\section{Continuity}

In order to expand our concepts of limits from sequences to functions on real numbers, we begin by defining the points on the real line we will be able to evaluate the future concepts.

\subsection{Limits of function}

\begin{definition}[Cluster point]
    Let $S \subseteq \R$. Then, $x \in \R$ is a cluster point of $S$ if $\forall \delta > 0, (x-\delta, x+ \delta) \cap S \setminus\{x\} \neq \varnothing$
\end{definition}

This notion can be further clarified by a few examples:
\paragraph{Examples}
\begin{enumerate}
    \item $S = \{1/n: n \in \N\}$: $0$ is a cluster point of $S$, since $1/n$ can be made arbitrary small, so $ (0 - \delta, 0 + \delta) \cap S \setminus \{0\} \neq \varnothing, \forall \delta > 0$.
    \item $S = (0,1)$ then $[0,1]$ is the set of cluster points of $S$.
    \item $S = \Q$ then $\R$ is the set of cluster points.
\end{enumerate}

\begin{theorem}
    Let $S \subseteq \R$, then $x$ is a cluster point of $S$ if, and only if, there exists a sequence $\{x_n\}$ of elements in $S \setminus \{x\}$ such that $x_n \to x$.
\end{theorem}

\begin{definition}[Function convergence]
    Consider $S \subseteq \R$, $c$ a cluster point of $S$, and $f: S \to \R$. Then, $f(x)$ converges to $L \in \R$ at $c$ if $\forall \varepsilon > 0, \exists \delta > 0$ such that if $x \in S$ and $0 < |x-c| < \delta$, then $|f(x) - L| < \varepsilon$. \\
    We can write $f(x) \to L$ as $x \to c$ or $\lim_{x \to c} f(x) = L$.
\end{definition}

\begin{theorem}[Uniqueness of the limit of a function]
    Let $c$ be a cluster point of $S \subseteq \R$ and $f: S \to \R$. If $f(x) \to L_1$ and $f(x) \to L_2$ as $x \to c$ then $L_1 = L_2$.
\end{theorem}

\begin{proof}
    Take $\varepsilon > 0$, since $f(x) \to L_1$ and $f(x) \to L_2, \exists \delta_1, \delta_2 \in \R$ such that if $x \in S$ with $0 < |x-c| < \delta_1$ and $0 < |x-c| < \delta_2$ we have $|f(x) - L_1| < \varepsilon/2$ and $|f(x) - L_2| < \varepsilon/2$. \\
    Choose $\delta = \min\{\delta_1, \delta_2\}$. Since $c$ is a cluster point of $S, \exists x_0 \in S$ such that $0 < |x_0-c| < \delta \longrightarrow |L_1-L_2| = |L_1 - f(x_0) + f(x_0) - L_2| \leq |L_1 - f(x_0)| + |f(x_0) - L_2| < \varepsilon$.
\end{proof}

\begin{theorem}
    Consider $c$ a cluster point in $S \subseteq \R$, and $f: S \to \R$. Then, the following statements are equivalent:
    \begin{itemize}
        \item $\lim_{x \to c} f(x) = L$ and,
        \item for every sequence $\{x_n\}$ in $S \setminus \{x\}$ such that $x_n \to c$, then $f(x_n) \to L$.
    \end{itemize}
\end{theorem}

\begin{proof}
    Proving each direction of the theorem individually:
    \begin{enumerate}
        \item Suppose $f(x) \to L$ as $x \to c$, then consider $\{x_n\}$ in $S \setminus \{x\}$ such that $x_n \to c$. Let $\varepsilon > 0, \exists \delta > 0$ such that $|f(x) - L| < \varepsilon$ if $x \in S$ and $0 < |x-c| < \delta$. Since $x_n \to c, \exists N \in \N$ such that $0 < |x_n-c| < \delta, \forall n \geq N$, since $|f(x) - L| \varepsilon, \forall 0 < |x-c| < \delta$ then $f(x_n) \to L$.
        \item Assuming the second part is false, for contradiction, $\exists \varepsilon_0 > 0$ such that $\forall \delta > 0, \exists x \in S$ such that $0 < |x-c| < \delta$ and $|f(x) - L| \geq \varepsilon_0$. Then, $\forall n \in \N, \exists x_n \in S$ such that $0 < |x_n - c| < 1/n$ and $|f(x_n) - L| \geq \varepsilon_0$. By the squeeze theorem we conclude $x_n \to c$ and $0 = \lim_{n \to \infty} |f(x_n) - L| \geq \varepsilon_0 > 0$ which is a contradiction.
    \end{enumerate}
\end{proof}

\begin{theorem}
    \begin{equation*}
        \lim \limits_{x \to 0} \sin (1/x) \textnormal { does not exist}
    \end{equation*}
\end{theorem}

\begin{proof}
    Let $x_n = \frac{2}{(2n-1)\pi}$. Then, $x_n \neq 0$ and $x_n \to 0$. Now,
    \begin{equation*}
        \sin (1/x_n) = \sin \frac{(2n-1) \pi}{2} = (-1)^{n+1}
    \end{equation*}
\end{proof}

\begin{theorem}
    \begin{equation*}
        \lim \limits_{x \to 0} x \sin(1/x) = 0
    \end{equation*}
\end{theorem}

\begin{proof}
    Suppose $x_n \neq 0$ and $x_n \to 0$. Then,
    \begin{equation*}
        0 \leq |x_n \sin(1/x_n)| = |x_n||\sin(1/x_n)| \leq |x_n|
    \end{equation*}
    By the squeeze theorem, $\lim _{n \to \infty} |x_n \sin(1/x_n)| = 0$
\end{proof}

\begin{theorem}
    Consider $c$ a cluster point in $S \subseteq \R$ and $f,g: S \to \R$, with $f(x) \leq g(x), \forall x \in S$. Suppose $\lim_{x \to c} f(x)$ and $\lim_{x \to c} g(x)$ both exist. Then,
    \begin{equation*}
        \lim \limits_{x \to c} f(x) \leq \lim \limits_{x \to c} g(x)
    \end{equation*}
\end{theorem}

\begin{proof}
    Define $L_1 = \lim_{x \to c} f(x)$ and $L_2 = \lim_{x \to c} g(x)$, and $\{x_n\}$ to be a sequence in $S \setminus \{c\}$ with $x_n \to c$. Then, $f(x_n) \leq g(x_n), \forall n \in \N$. So,
    \begin{equation*}
        L_1 = \lim \limits_{n \to \infty} f(x_n) \leq \lim \limits_{n \to \infty} g(x_n) = L_2
    \end{equation*}
\end{proof}

\begin{definition}[Convergence from the left]
    Consider $c$ to be a cluster point of $S \cap (-\infty, c)$ with $S \subseteq \R$. Then, we say $f(x)$ converges to $L$ from the left (or as $x \to c^-$) if $\forall \varepsilon > 0, \exists \delta >0$ such that if $x \in S$ and $c - \delta < x < c$ we obtain $|f(x) - L| < \varepsilon$. \\
    We denote it by $L = \lim_{x \to c^-} f(x)$.
\end{definition}

\begin{definition}[Convergence from the right]
    Consider $c$ to be a cluster point of $S \cap (c, \infty)$ with $S \subseteq \R$. Then, we say $f(x)$ converges to $L$ from the right (or as $x \to c^+$) if $\forall \varepsilon > 0, \exists \delta >0$ such that if $x \in S$ and $c < x < c + \delta$ we obtain $|f(x) - L| < \varepsilon$. \\
    We denote it by $L = \lim_{x \to c^+} f(x)$.
\end{definition}

\paragraph{Example} Consider
\begin{equation*}
    f(x) = \begin{cases}
    1 \textnormal{ if } x > 0 \\
    0 \textnormal{ if } x < 0
    \end{cases}
\end{equation*}
Then, $\lim_{x \to 0^-} f(x) = 0$ and $\lim_{x \to 0^+} f(x) = 0$, despite $f(0)$ being undefined.

\begin{theorem}
    Consider $c$ a cluster point of $S\cap(-\infty, c)$ and $S\cap(c, \infty)$, with $S \subseteq \R$. Then, $c$ is a cluster point of $S$. Or equivalently:
    \begin{equation*}
        \lim \limits_{x \to c} f(x) = L \longleftrightarrow \lim \limits_{x \to c^-} f(x)= \lim \limits_{x \to c^+} f(x) = L
    \end{equation*}
\end{theorem}

\subsection{Continuity of a function}

As shown in a past example, it is possible that $\lim_{x \to c} f(x) \neq f(c)$. In other words, it is possible that a limit of a function as $x \to c$ (or $x \to c^-$, $x \to c^+$) differs from $f(c)$. Continuity links the two concepts.

\begin{definition}[Continuous function]
    Consider $c \in S \subseteq \R$ a cluster point. We say $f$ is continuous at $c$ if $\forall \varepsilon > 0, \exists \delta > 0$ such that if $x \in S$ with $|x-c| < \delta$ then $|f(x)-f(c)| < \varepsilon$. If $f$ is continuous at all points of $U \subseteq S$ then $f$ is continuous on $U$.
\end{definition}

\begin{theorem}
    Consider $c \in S \subseteq \R$, and $f: S \to \R$, then:
    \begin{enumerate}
        \item if $c$ is not a cluster point of $f$, then $f$ is continuous at $c$,
        \item if $c$ is a cluster point of $f$, then $f$ is continuous at $c$ if, and only if, $\lim_{x \to c} f(x) = f(c)$,
        \item $f$ is continuous at $c$, and only if, for all sequence $\{x_n\}$ in $S$ with $x_n \to c$ then $f(x_n) \to f(c)$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Proving each statement:
    \begin{enumerate}
        \item Consider $\varepsilon > 0$, since $c$ is not a cluster point of $S$ then $\exists \delta >0$ such that $(c-\delta, c+ \delta) \cap S = \{c\}$, so if $x \in S$ and $|x-c| < \delta$ then $x = c$ and $|f(x) - f(c)| < \varepsilon$.
        \item Proving each direction of the statement:
            \begin{itemize}
                \item $(\Longleftarrow)$ If $\lim_{x \to c} f(x) = f(c)$ then $\forall \varepsilon > 0, \exists \delta > 0$ such that if $x \in S$ and $|x-c| < \delta$ then $|f(x) - f(c)| < \varepsilon$.
                \item $(\Longrightarrow)$ If $f$ is continuous at $c$ then $\forall \varepsilon > 0, \exists \delta > 0$ such that if $x \in S$ with $|x-c| < \delta$ then $|f(x) - f(c)| < \varepsilon$.
            \end{itemize}
        \item Proving each direction of the statement:
            \begin{itemize}
                \item $(\Longrightarrow)$, let $\{x_n\}$ in $S$ with $x_n \to c$. Take $\varepsilon > 0$, since $f$ is continuous at $c$, $\exists \delta > 0$ such that if $|x-c| < \delta$ with $x \in S$ then $|f(x_n) - f(c)| < \varepsilon$. Since $x_n \to c, \exists N \in \N$ such that $|x_n-c| <  \delta, \forall n \geq N$. So, $|x_n-c| < \delta \longrightarrow |f(x_n) - f(c)| < \varepsilon$.
                \item $(\Longleftarrow)$ For contradiction, assume $f$ is not continuous at $c$, then $\exists \varepsilon_0 > 0$ such that $\forall \delta > 0, \exists x \in S$ such $|x-c| < \delta$ and $|f(x) - f(c)| \geq \varepsilon_0$. Thus, $\forall n \in N, \exists x_n \in S$ such that $|x_n-c| < 1/n$ and $|f(x_n) -  f(c)| \geq \varepsilon_0$. Thus, by the squeeze theorem $|x_n - c| \to 0$ and $x_n \to c$ which implies $f(x_n) \to x$ which is a contradiction.
            \end{itemize}
    \end{enumerate}
\end{proof}

\begin{definition}[Bounded function]
    A function $f: S \to \R$ is bounded if $\exists M \geq 0$ such that $|f(x)| \leq M, \forall x \in S$.
\end{definition}

\begin{theorem}
    If $f: [a,b] \to \R$ is continuous at $[a,b]$ then it is bounded.
\end{theorem}

\begin{proof}
    For contradiction, assume $f$ is continuous but not bounded. Then, $\forall n \in \N, \exists x_n \in [a,b]$ such that $|f(x)| \geq n$. By the Bolzano-Weierstrass theorem, there exists a subsequence $\{x_{n_k}\}$ of $\{x_n\}$ with $x \in \R$ and $x_{n_k} \to x$. Since, $x_{n_k} \in [a,b], \forall k \in \N$ then $x \in [a,b]$. Given $f$ is continuous
    \begin{equation*}
        f(x) = \lim \limits_{k \to \infty} f(x_{n_k}) \Longrightarrow |f(x)| = \lim \limits_{k \to \infty} |f(x_{n_k})|
    \end{equation*}
    Hence, $\{|f(x_{n_k})\}$ is bounded and so is $\{n_k\}$ since $n_k \leq |f(x_{n_k})|$, from the definition of a subsequence $k \leq x_k, \forall k \in N$, contradicting the initial claim.
\end{proof}

\begin{theorem}[Min-max theorem or Extreme value theorem]
    Consider $f: [a,b] \to \R$. If $f$ is continuous on $[a,b]$ then it achieves an absolute maximum and absolute minimum on $[a,b]$.
\end{theorem}

\begin{proof}
    For the absolute maximum, if $f$ is continuous then $f$ is bounded. Thus, $E = \{ f(x): x \in [a,b]\}$ is bounded. Let $L = \sup E$ then,
    \begin{itemize}
        \item $L$ is an upper bound for $E$
        \item There exists a sequence $\{f(x_n)\}$ with $x_n \in [a,b]$ such that $f(x_n) \to L$
    \end{itemize}
    By the Bolzano-Weierstrass theorem, there exists a subsequence $\{x_{n_k}\}$ of $\{x_n\}$ and $d \in [a,b]$ such that $x_n \to d$ as $k \to \infty$. Hence,
    \begin{equation*}
        f(d) = \lim \limits_{k \to \infty} f(x_{n_k}) = \lim \limits_{n \to \infty} f(x_n) = L
    \end{equation*}
    by the continuity of $f$ on $[a,b]$. So, $f$ achieves an absolute maximum at $d$.
    The proof for the absolute minimum follows similarly.
\end{proof}

\begin{theorem}
    Consider $f: [a,b] \to \R$. If $f(a) < 0$ and $f(b) > 0$, then $\exists c \in (a,b)$ such that $f(c) = 0$
\end{theorem}

\begin{proof}
    Let $a_1 = a$ and $b_1 = b$. Define $a_n, b_n$ as follows:
    \begin{itemize}
        \item If $f((a_{n-1} + b_{n-1})/2) \geq 0$ then $a_n = a_{n-1}$ and $b_n = (a_{n-1} + b_{n-1})/2$,
        \item If $f((a_{n-1} + b_{n-1})/2 < 0$ then $a_n = (a_{n-1}+b_{n-1})/2$ and $b_n = b_{n-1}$.
    \end{itemize}
    In this way, we obtain:
    \begin{enumerate}
        \item $a \leq a_n \leq a_{n+1} \leq b_{n+1} \leq b_n \leq b, \forall n \in N$,
        \item $b_{n+1} - a_{n+1} = (b_n - a_n)/2, \forall n \in \N$,
        \item $f(a_n) \leq 0$ and $f(b_n) \geq 0, \forall n \in N$.
    \end{enumerate}
    From 1., $\{a_n\}$ and $\{b_n\}$ are bounded and monotone increasing and decreasing respectfully. Thus, $\exists c, d \in [a,b]$ such that $a_n \to c$ and $b_n \to d$. By 2.,
    \begin{equation*}
        b_n - a_n = \frac{b_{n-1} - a_{n-1}}{2} = \frac{1}{4}(b_{n-2} - a_{n-2}) = ... = \frac{1}{2^{n-1}}(b-a)
    \end{equation*}
    And,
    \begin{equation*}
        d - c = \lim \limits_{n \to \infty} (b_n - a_n) = \lim \limits_{n \to \infty} \frac{1}{2^{n-1}} (b-a) = 0 \Longrightarrow d = c
    \end{equation*}
    So, $a_n \to c$ and $b_n \to c$. By 3., $f(c) = \lim_{n \to \infty} f(a_n) \leq 0$ and $f(c) = \lim_{n \to  \infty} f(b_n) \geq 0$. Therefore, $f(c) = 0$.
\end{proof}

\begin{theorem}[Bolzano intermediate value theorem]
    Consider $f: [a,b] \to \R$ continuous. If $f(a) < f(b)$ with $y \in (f(a), f(b)), \exists c \in (a,b)$ such that $f(c) = y$. Else, if $ f(b) < f(a)$ with $y \in (f(b), f(a))$ then $\exists c \in (a,b)$ such that $f(c) = y$.
\end{theorem}

\begin{proof}
    Suppose $f(a) < f(b)$ with $y \in (f(a), f(b))$. Define $g(x) = f(x) - y$. Then, $f(x) = c \Longleftrightarrow g(x) = 0$ and $g: [a,b] \to \R$ is continuous, more importantly $g(a) = f(a) - y < 0$ and $g(b) = f(b) - y > 0$, then by the previous theorem $\exists c \in (a,b)$ such that $g(c) = y$ which is equivalent to $f(c) = y$. The proof for $f(b)<f(a)$ follows similarly.
\end{proof}

\begin{theorem}
    Consider $f: [a,b]  \to \R$ to be continuous. Take $c \in [a,b]$ to be where $f$ achieves a minimum value in $[a,b]$ and $d \in [a,b]$ to be where $f$ achieves a maximum value in $[a,b]$. Then, $f([a,b]) = [f(c), f(d)]$. Putting it in words: every value between the maximum and minimum is achieved.
\end{theorem}

\begin{proof}
    It is clear that $f([a,b]) \subseteq [f(c), f(d)]$. By the intermediate value theorem applied to $f: [c,d] \to \R$, we obtain $[f(c), f(d)] \subseteq f([c,d]) \subset f([a,b])$. Therefore, $f([a,b]) = [f(c), f(d)]$.
\end{proof}

\subsection{Uniform continuity}

\begin{definition}[Uniform continuity]
    Consider $f: S \to \R$. Then $f$ is continuous on $S$ if $\forall \varepsilon > 0, \exists \delta = \delta(\varepsilon) > 0$ such that $|x-c| < \delta$ implies $|f(x) - f(c)| < \varepsilon, \forall x \in S$.    
\end{definition}

\begin{theorem}
    Consider $f: [a,b] \to \R$, then $f$ is continuous if, and only if, $f$ is uniformly continuous.
\end{theorem}

\begin{proof}
    Proving each direction of the statement:
    \begin{itemize}
        \item $(\Longrightarrow)$: Suppose $f$ is continuous and assume for contradiction that $f$ is not uniformly continuous. Then, $\exists \varepsilon_0 > 0$ such that $\forall n \in \N, \exists x_n, c_n \in [a,b]$ such that $|x_n-c|<1/n$ and $|f(x_n) - f(c_n)| \geq \varepsilon_0$. \\
        By the Bolzano-Weierstrass theorem, there exists a subsequence $\{x_{n_k}\}$ of $\{x_n\}$ and $x \in [a,b]$ such that $x_{n_k} \to x$. Similarly, there also exists a subsequence $\{c_{n_k}\}$ of $\{c_n\}$ and $c \in [a,b]$ such that $c_{n_k} \to c$. And also, the subsequence $\{x_{n_{k_k}}\}$ of $\{x_{n_k}\}$ satisfies $x_{n_{k_j}} \to x$. Then, $|x-c| = \lim_{j \to \infty} |x_{n_{k_j}} - c_{n_{k_j}}| \leq \lim_{j \to \infty} 1/n_{k_j} - 0$. \\
        Thus, $x = c$. But since $f$ is continuous at $c$, $0 = |f(c) - f(c)| = \lim_{j \to \infty} |f(x_{n_{k_j}}) - f(c_{n_{k_j}})| \geq \varepsilon_0$ which is a contradiction to the initial claim.
    \end{itemize}
\end{proof}

\section{Differentiation}

\subsection{Definition and properties}

\begin{definition}[Derivative]
    Let $I$ be an interval with $f: I \to \R$ and $c \in I$. Then, $f$ is differentiable at $c$ if the limit
    \begin{equation}
        \lim \limits_{x \to c} \frac{f(x) - f(c)}{x-c}
    \end{equation}
    exists, in this case we write:
    \begin{equation}
        f'(c) = \lim \limits_{x \to c} \frac{f(x) - f(c)}{x-c}
    \end{equation}
    Furthermore, if $f$ is differentiable $\forall c \in I$ then we write the derivative as $f'$, or $f'(x)$ or $\frac{\dint f}{\dint x}$.
\end{definition}

\paragraph{Example} For all $n \in \N$, the derivative of the power function $f: \R \to \R$, $f(x) = \alpha x^n$ is given by $f'(c) = \alpha n c^{n-1}, \forall c \in \R$.

\begin{proof}
    First, note that $\forall n \in \N$:
    \begin{equation*}
        (x-c) \sum \limits_{j=0}^{n-1} x^{n-1-j}c^j = \sum \limits_{j=0}^{n-1}x^{n-j}c^j - \sum \limits_{j=0}^{n-1} x^{n-1-j}c^{j+1}
    \end{equation*}
    Defining $l = j + 1$:
    \begin{align*}
        (x-c) \sum \limits_{j=0}^{n-1} x^{n-1-j}c^j &= \sum \limits_{l=1}^{n}x^{n-j}c^j - \sum \limits_{j=0}^{n-1} x^{n-l}c^{l} \\
        &= x^{n-0}c^0 - x^{n-n}c^n \\
        &= x^n - c^n
    \end{align*}
    Therefore,
    \begin{equation*}
        f'(c) = \lim \limits_{x \to c} \frac{\alpha x^n - \alpha c^n}{x-c} = \alpha \lim \limits_{x \to c} \sum \limits_{j=0}^{n-1} x^{n-1-j}c^j = \alpha \sum \limits_{j=0}^{n-1} c^{n-1-j}c^j = \alpha n c^{n-1}
    \end{equation*}
\end{proof}

\begin{theorem}
    If the function $f: I \to \R$ is differentiable at $c \in I$, then it is also continuous at $c$.
\end{theorem}

\begin{proof}
    Since every point of $I$ is also a cluster point, then $f$ is continuous at $c \in I$ if, and only if, $\lim_{x \to c} f(x) = f(c)$. Now, 
    \begin{align*}
        \lim \limits_{x \to c} f(x) &= \lim \limits_{x \to c} (f(x) - f(c) + f(c)) \\
        &= \lim \limits_{x \to c} \left( (x-c)\frac{f(x)-f(c)}{x-c} + f(c)\right) \\
        &= 0 \cdot f'(c) + f(c) = f(c)
    \end{align*}
\end{proof}

\subsection{Weierstrass' function}

Continuity seems to be a prerequisite for the differentiation of a function. However, we may be tempted to take it as a sufficient condition, which unfortunately is not the case. This behaviour can be seen by an example.

\paragraph{Example} Consider $f(x) = |x|$. Then, $f$ is not differentiable at $0$, even though it is continuous at $0$.

\begin{proof}
    Consider a sequence $\{x_n\}$ such that $x_n \to 0$ and
    \begin{equation*}
        \lim \limits_{n \to \infty} \frac{f(x_n) - f(0)}{x_n - 0}
    \end{equation*}
    does not exist. Let $x_n = (-1)^n/n$. Then, $x_n \to 0$ and 
    \begin{equation*}
        \frac{f(x_n)-f(0)}{x_n - 0} = \frac{|(-1)^n/n|}{(-1)^n/n} =(-1)^n
    \end{equation*}
    Hence, $\lim_{n \to \infty} (-1)^n$ does not exist.
\end{proof}

It is clear that a function may be continuous, and yet non-differentiable at some point. However, if $f: \R \to \R$ is continuous at $\R$, is there a point $c \in \R$ such that $f$ is differentiable at $c$. The answer is no. There exists a function everywhere continuous and nowhere differentiable, called the Weierstrass' function.

In order to prove such function exists and fulfils the description above it is necessary to gather some tools, the following theorems are presented with this goal.

\begin{theorem}
    For the cosine function, it is true that:
    \begin{enumerate}
        \item $\forall x, y \in \R, |\cos x - \cos y| \leq |x - y|$
        \item For $c \in \R$ and $k \in \N$, $\exists y \in (c + \pi/k, c + 3\pi/k)$ such that $|\cos(kc) - \cos(ky)| \leq 1$.
    \end{enumerate}
\end{theorem}

\begin{theorem}
    For $a, b, c \in \R, |a + b + c| \leq |a| - |b| - |c|$.
\end{theorem}

\begin{proof}
    This follows from the triangle inequality:
    \begin{equation*}
        |a| = |a + b + c + (-b) + (-c)| \leq |a + b + c| + |b + c| \leq |a + b + c| + |b| + |c|
    \end{equation*}
\end{proof}

\begin{theorem}
    Consider the function:
    \begin{equation}
        f(x) = \sum \limits_{k = 0}^\infty \frac{\cos (160^k x)}{4^k}
    \end{equation}
    Then,
    \begin{enumerate}
        \item $\forall x \in \R, f(x)$ is absolutely convergent,
        \item $f(x)$ is bounded and continuous.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Proving each statement:
    \begin{enumerate}
        \item First, note that
            \begin{equation*}
                \left | \frac{\cos (160^k x)}{4^k}\right | \leq 4^{-k}, \forall k \in \N
            \end{equation*}
            Hence, the the comparison test, 
            \begin{equation*}
                \sum \limits_{k=0}^\infty \left | \frac{\cos (160^k x)}{4^k}\right |
            \end{equation*}
            converges.
        \item We begin by noticing:
        \begin{equation*}
            |f(x)| \leq \sum \limits_{k=0}^\infty \frac{|\cos (160^k)|}{4^k} \leq \sum \limits_{k=0}^\infty \frac{1}{4^k} = \frac{4}{3}
        \end{equation*}
        Hence, $f$ is bounded.\\
        Next, suppose $c \in \R$ and $x_n \to c$. Note that $\{|f(x_n) - f(c)|\}$ is bounded. Thus,
        \begin{equation*}
            \lim \limits_{n \to \infty} |f(x_n) - f(c)| = 0 \Longleftrightarrow \limsup \limits_{n \to \infty} |f(x_n) - f(c)| = 0
        \end{equation*}
        It is necessary to show $\limsup_{n \to \infty} |f(x_n) - f(c)| \leq \varepsilon, \forall \varepsilon > 0$. Choose $N_0 \in \N$ such that $\sum_{k=N_0 + 1}^\infty 4^{-k} < \varepsilon/2$. Then,
        \begin{align*}
            &\limsup \limits_{n \to \infty} |f(x_n) - f(c)| \\
            &= \limsup \limits_{n \to \infty} \left |
                \sum \limits_{k=0}^{N_0} \frac{\cos (160^k x_n)}{4^k} - \frac{\cos (160^k c)}{4^k} + 
                \sum \limits_{k=N_0 + 1}^\infty \frac{\cos (160^k x_n)}{4^k} - \frac{\cos (160^k c)}{4^k}
            \right | \\
            &\leq \limsup \limits_{n \to \infty} \sum \limits_{k = 0}^{N_0} 4^{-k} |\cos (160^k x) - \cos( 160^k c) + \sum \limits_{k = N_0 + 1}^\infty 4^{-k} |\cos (160^k x) - \cos( 160^k c) \\
            &\leq \limsup \limits_{n \to \infty} \left ( \sum \limits_{k=0}^{N_0} 4^{-k} \right ) |x_n - c| + \varepsilon = \varepsilon
        \end{align*}
    \end{enumerate}
\end{proof}

\begin{theorem}[Weierstrass function]
    The function:
    \begin{equation}
        f(x) = \sum \limits_{k = 0}^\infty \frac{\cos(160^k x)}{4^k}
    \end{equation}
    is nowhere differentiable.
\end{theorem}

\begin{proof}
    Consider $c \in \R$, our goal is to find a sequence $\{x_n\}$ with $x_n \to c$ such that
    \begin{equation*}
        \left \{
            \frac{f(x_n) - f(c)}{x_n - c}
        \right \}
    \end{equation*}
    is unbounded. From one of the previous theorem, $\forall n \in \N, \exists x_n$ such that $\pi/160^n < x_n - c < 3\pi/160^n$ and $|\cos (160^n c) - \cos (160^n x_n)| \geq 1$. So, $x_n \neq 0, \forall n \in \N$ and $|x_n - c| \leq 3 \pi/160^n \to 0$. Define:
    \begin{equation*}
        f_k(x) = \frac{\cos (160^k x)}{4^k}
    \end{equation*}
    So, $f(x) = \sum f_k(x)$. Thus, define:
    \begin{align*}
        f(c) - f(x_n) &= f_n(c) - f_n(x_n) + \sum \limits_{k=0}^{n-1}(f_k(c) - f_k(x_n)) + \sum \limits_{k=n}^\infty(f_k(c) - f_k(x_n)) \\
        &= a_n + b_n + c_n
    \end{align*}
    Then, $|a_n| = 4^{-n} |\cos (160^k x_n) - \cos (160^k c)| \geq 4^{-n}$. And,
    \begin{align*}
        |b_n| &\leq \sum \limits_{k=0}^{n-1} 4^{-k}|\cos (160^k c) - \cos (160^k x_n)|) \\
        &\leq \sum \limits_{k=0}^{n-1}4^{-k} 160^k |x_n - c| \\ 
        &\leq \frac{3 \pi}{160^n} \sum \limits_{k=0}^{n-1}40^k \\
        &= \frac{3 \pi}{160^n} \frac{40^n - 1}{39} \leq \frac{4^{-n+1}}{13}
    \end{align*}
    And,
    \begin{align*}
        |c_n| &\leq \sum \limits_{k = n+1}^\infty 4^{-k}(|\cos(160^k c)| + |\cos (160^k x_n)|) \\
        &\leq 2 \sum \limits_{k = n+1}^\infty 4^{-k} \\
        &= 2\cdot 4^{-n+1}\frac{4}{3} = 4^{-n} \frac{2}{3}
    \end{align*}
    Combining the former inequalities, we obtain:
    \begin{equation*}
        |f(c) - f(x_n)| \geq 4^{-n} \left(1 - \frac{4}{13} - \frac{2}{3} \right) = 4^{-n}\frac{1}{39}
    \end{equation*}
    Therefore,
    \begin{equation*}
        \frac{|f(c) - f(x_n)|}{|c-x_n|} \geq \frac{160^n}{3\pi} 4^{-n}\frac{1}{39} = \frac{40^n}{117 \pi}
    \end{equation*}
    Thus, the sequence is unbound and therefore does not converge for any $x \in \R$ and the derivative does not exist.
\end{proof}

\subsection{Differentiation rules and theorems}

\begin{theorem}[Chain rule]
    Consider $f: A \to B$ and $g: B \to \R$, with $f$ differentiable at $c \in A$ and $g$ differentiable at $f(c) \in B$. Then, $(g \circ f)'(c) = g'(f(c))f'(c)$.
\end{theorem}

\begin{proof}
    Let $h(x) = (g \circ f)(x)$ and $d = f(c)$. Define:
    \begin{equation*}
        u(y) = \begin{cases}
            \frac{g(y) - g(d)}{y - d} \text{ if } y \neq d \\
            g'(d) \: \: \: \: \: \: \text{ if } y = d
        \end{cases}
    \end{equation*}
    and,
    \begin{equation*}
        v(x) = \begin{cases}
            \frac{f(x) - f(c)}{x - c} \text{ if } x \neq c \\
            f'(c) \: \: \: \: \: \: \text{ if } x = c
        \end{cases}
    \end{equation*}
    Then,
    \begin{equation*}
        \lim \limits_{y \to d} u(y) = \lim \limits_{y \to d} \frac{g(y) - g(d)}{y - d} = g'(d) = u(d)
    \end{equation*}
    and,
    \begin{equation*}
        \lim \limits_{x \to c} v(x) = \lim \limits_{x \to c} \frac{f(x) - f(c)}{x - c} = d'(c) = v(c)
    \end{equation*}
    Which shows $u(y)$ and $v(x)$ are continuous. Now, $g(y) - g(d) = u(y)(y-d)$ and $f(x) - f(c) = v(x)(x-c)$. Then, $h(x) - h(c) = g(f(x)) - g(f(c)) = g(f(x)) - g(d) = u(f(x))(f(x) - f(c)) = u(f(x))v(x)(x-c)$. So, 
    \begin{align*}
        \lim \limits_{x \to c} \frac{h(x) - h(c)}{x - c} &= \lim \limits_{x \to c} u(f(x))v(x) \\
        &= u(f(c))v(c) \\
        &= f'(g(c))g'(c)
    \end{align*}
\end{proof}

\begin{theorem}
    Consider $f: I \to \R$ and $g: I \to \R$, both differentiable at $c \in I$. Then,
    \begin{enumerate}
        \item $(\alpha f)'(c) = \alpha f'(c), \forall \alpha \in \R$,
        \item $(f + g)'(c) = f'(c) + g'(c)$,
        \item $(fg)'(c) = f'(c)g(c) + f(c)g'(c)$,
        \item $(f/g)'(c) = \frac{f'(c)g(c) - f(c)g'(c)}{[g(c)]^2}$, provided $g(c) \neq 0$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Proving each statement:
    \begin{enumerate}
        \item This result follows directly from the definition:
            \begin{equation*}
                (\alpha f)'(c) = \lim \limits_{x \to c} \frac{(\alpha f)(x) - (\alpha f)(c)}{x - c} = \alpha \frac{f(x) - f(c)}{x-c} = \alpha f'(c)
            \end{equation*}
        Considering the algebraic properties of limits.
        \item Again, from the definition:
            \begin{equation*}
                (f + g)'(c) = \lim \limits_{x \to c}\frac{(f + g)(x) - (f + g)(c)}{x - c} = \lim \limits_{x \to c} \frac{f(x) - f(c)}{x-c} + \lim \limits_{x \to c}\frac{g(x) - g(c)}{x-c} = f'(c)+g'(c)
            \end{equation*}
        \item First, note:
            \begin{equation*}
                \frac{f(x)g(x) - f(c)g(c)}{x - c} = \frac{f(x) - f(c)}{x- c}g(x) + f(c) \frac{g(x) - g(c)}{x - c}
            \end{equation*}
            Then, taking $\lim_{x \to c}$, we obtain: $ (fg)'(c) = f'(c)g(c) + f(c)g'(c)$.
        \item Consider $h(x) = 1/g(x)$. By the chain rule $h'(c) = -g'(c)/[g(c)]^2$. Then, $(f/g)'(c) = (fh)'(c) = f'(c)h(c) + f(c)h'(c) = [f'(c)/g(c) - f(c)[g(c)]^2/g'(c)] = [f'(c)g(c) - f(c)g'(c)]/[g(c)]^2$.
    \end{enumerate}
\end{proof}

\begin{definition}[Relative maximum/minimum]
    Consider $S \subseteq \R$ and $f: S \to \R$. Then, $f$ has a relative maximum at $c \in S$ if $\exists \delta > 0$ such that $\forall x \in S: |x-c| < \delta$ then $f(x) \leq f(c)$. The definition of minimum follows analogously.
\end{definition}

\begin{theorem}
    If $f:[a,b] \to \R$, $f$ has a relative min or max at $c \in (a,b)$ and $f$ is differentiable at $c$, then: $f'(c) = 0$.
\end{theorem}

\begin{proof}
    If $f$ has a relative maximum at $c \in (a,b)$, then $\exists \delta > 0$ such that $f(c) \leq f(x), \forall x in (c- \delta, c + \delta)$, with $x \in [a,b]$. Let 
    \begin{equation*}
        x_n = c - \frac{\delta}{2n} \in (c- \delta, c)
    \end{equation*}
    Then, $x_n \to c$, so:
    \begin{equation*}
        f'(c) = \lim \limits_{n \to \infty} \frac{f(x_n) - f(c)}{x_n - c} \geq 0
    \end{equation*}
    Now, define:
    \begin{equation*}
        y_n = c + \frac{\delta}{2n} \in (c, c+\delta)
    \end{equation*}
    Then, $y_n \to c$, and
    \begin{equation*}
        f'(c) = \lim \limits_{n \to \infty}\frac{(f(y_n) - f(c))}{y_n - c} \leq 0
    \end{equation*}
    Therefore, $f'(c) = 0$.
\end{proof}

\begin{theorem}[Rolle's theorem]
    Consider $f: [a,b] \to \R$ and $f$ differentiable in $(a,b)$, additionally if $f(a) = f(b)$, then $\exists c \in (a,b)$ such that $f'(c) = 0$.
\end{theorem}

\begin{proof}
    Let $Y = f(a) = f(b)$. Since $f$ is continuous $\exists c_1, c_2 \in [a,b]$ to be a relative maximum and a relative minimum, respectfully. Then if $f(c_1) > Y$ then $ c_1 \in (a,b)$ and $f'(c_1) = 0$. Similarly, if $f(c_2) < Y$ then $c_2 \in (a,b)$ and $f'(c_2) = 0$. If $f(c_1) \leq Y \leq f(c_2)$ then $f(x) = Y, \forall x \in [a,b]$, so $f'(c) - 0$ for any $c \in (a,b)$.
\end{proof}

\begin{theorem}[Mean value theorem]
    Consider $f: [a,b] \to \R$ to be continuous and differentiable in $(a,b)$. Then, $\exists c \in (a,b)$ such that $f(b) - f(a) = f'(c)(b - a)$.
\end{theorem}

\begin{proof}
    Define
    \begin{equation*}
        g(x) = f(x) - f(b) + \frac{f(b) - f(a)}{b - a}(b - x)
    \end{equation*}
    Then, $g(a) = g(b) = 0$. Thus, by the Rolle's theorem, $\exists c \in (a,b)$ such that $g'(c) = 0$. Hence,
    \begin{equation*}
        g'(c) = 0 = f'(c) - \frac{f(b) - f(a)}{b-a}
    \end{equation*}
\end{proof}

\begin{theorem}
    If $f: I \to \R$ is differentiable and $f'(x) = 0, \forall x \in I$ then $f$ is constant.
\end{theorem}

\begin{proof}
    Let $a,b \in I$ with $a < b$. Then, $f$ is continuous on $[a,b]$ and differentiable on $(a,b)$. So, by the previous theorem, $\exists c \in (a,b)$ such that $f(b) - f(a) = (b-a)f'(c) = 0$. Hence, $f(b) = f(a), \forall a, b \in I$ such that $a < b$.
\end{proof}

\begin{theorem}
    Consider $f: I \to \R$ differentiable, then:
    \begin{enumerate}
        \item $f$ is increasing if, and only if, $f'(x) \geq 0, \forall x \in I$, and
        \item $f$ is decreasing if, and only if, $f'(x) \leq 0, \forall x \in I$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Proving $f$ is increasing if $f'(x) \geq 0$.
    \begin{itemize}
        \item $(\Longleftarrow)$: Suppose $f'(x) \geq 0, \forall x \in I$. Then, let $a,b \in I$ with $a < b$. By the mean value theorem, $\exists c \in (a,b)$ such that $f(b) - f(a) = (b-a)f'(c) \geq 0 \Longrightarrow f(a) \leq f(b)$.
        \item $(\Longrightarrow)$: Suppose $f$ is increasing. Let $c \in $ and $\{x_n\}$ be a sequence in $I$ such that $x_n \to c$, with $x_n < c, \forall n \in \N$. Then, $f(x_n) - f(c) \leq 0, \forall n \in N$, and by consequence:
            \begin{equation*}
                f'(c) = \lim \limits_{n \to \infty} \frac{f(x_n) - f(c)}{x_n - c} \geq 0
            \end{equation*}
            On the other hand, if $\{x_n\}$ is such that $x_n \to c$ and $x_n > c, \forall n \in \N$ then: $f(x_n) - f(c) \geq 0, \forall n \in \N$, and:
            \begin{equation*}
                f'(c) = \lim \limits_{n \to \infty} \frac{f(x_n) - f(c)}{x_n - c} \geq 0
            \end{equation*}
            In either case, $f'(c) \geq 0$.
    \end{itemize}
    The proof for the decreasing function follows from taking $-f$ increasing, which is equivalent to $f$ decreasing.
\end{proof}

\subsection{Smoothness and Taylor's theorem}

\begin{definition}
    Consider $f: I \to \R$. Then, $f$ is $n$ times differentiable on $J \subseteq I$ if $f'$, $f''$, ..., $f^(n)$ exist at every point of $J$. The $n$ derivative of $f$ is denoted by $f^(n)$.
\end{definition}

\begin{theorem}[Taylor's theorem]
    Suppose $f: [a,b] \to \R$ is continuous and has $n$ continuous derivatives on $[a,b]$ such that $f^{(n+1)}$ exists on $(a,b)$. Given $x, x_0 \in [a,b]$, there exists $c \in (a,b)$ such that:
    \begin{equation}
        f(x) = \sum \limits_{k = 0}^n \frac{1}{k!}f^{(k)}(x_0)(x-x_0)^k + \frac{f^{(n+1)}(c)}{(n+1)!}(x-x_0)^{n+1}
    \end{equation}
    Denote the large sum as $P_n(x)$ and the remainder as $R_n(x)$.
\end{theorem}

\begin{proof}
    Let $x, x_0 \in [a,b]$. If $x = x_0$ then any $c$ satisfies the theorem. Suppose $x \neq x_0$. Define:
    \begin{equation*}
        M_{x, x_0} = \frac{f(x) - P_n(x)}{(x-x_0)^{n+1}}
    \end{equation*}
    Then, $f(x) = P_n(x) + M_{x, x_0}(x-x_0)^{n+1}$. And $f^{(k)}(x_0) = P^{(k)}(x_0), \forall 0 \leq k \leq n$. Let $g(s) = f(x) - P_n(s) - M_{x, x_0}(s-x_0)^{n+1}$, then:
    \begin{eqnarray*}
        g(x_0) &=& f(x_0) - P_n(x_0) - M_{x,x_0}(x-x_0)^{n+1} = 0 \\
        g'(x_0) &=& f'(x_0) - P'_n(x_0) - M_{x,x_0}(n+1)(x-x_0)^{n} = 0 \\
        g''(x_0) &=& f''(x_0) - P''_n(x_0) - M_{x,x_0}(n+1)n(x-x_0)^{n-1} = 0 \\
        &...& \\
        g^{(n)}(x_0) &=& f^{(n)}(x_0) - P^{(n)}_n(x_0) - M_{x,x_0}(n+1)!(x-x_0) = 0
    \end{eqnarray*}
    Since $g(x) = 0$ and $g(x_0) = 0$, by the Mean value theorem, there exists $x_1 \in (x_0, x)$ such that $g'(x_1) = 0$. Thus, $g'(x_0) = 0$ and $g'(x_1) = 0$. By consequence, there exists $x_2 \in (x_0, x_1)$ such that $g''(x_2) = 0$. Preceding similarly, we find $x_n \in (x_0, x_{n-1})$ such that $g^{(n)}(x_n) = 0$. Finally, $g^{(n)}(x_0) = 0$ and $g^{(n)}(x_n) = 0$ which implies $\exists c \in (x_0, x_n)$ such that $g^{(n+1)}(c) = 0$. So,
    \begin{equation*}
        \frac{\dint ^{n+1}}{\dint s^{n+1}} M_{x, x_0}(s - x_0)^{n+1} = M_{x, x_0}(n+1)!
    \end{equation*}
    Additionally, $P_n^{(n+1)}(c) = 0$ since $P_n(x)$ is a polynomial with degree $n$. Hence,
    \begin{equation*}
        0 = g^{(n+1)}(c) = f^{(n+1)}(c) - M_{x, x_0}(n+1)! \Longrightarrow M_{x, x_0} = \frac{f^{(n+1)}(c)}{(n+1)!}
    \end{equation*}
    Thus,
    \begin{equation*}
        f(x) = P_n(x) + \frac{f^{(n+1)}(c)}{(n+1)!}(x-x_0)^{n+1}
    \end{equation*}
    
\end{proof}

\begin{theorem}[Second derivative test]
    Suppose $f: (a,b) \to \R$ has two continuous derivatives. If $x_0 \in (a,b)$ is such that $f'(x_0) = 0$ then:
    \begin{itemize}
        \item If $f''(x_0) > 0$, then $f$ has a relative minimum at $x_0$,
        \item If $f''(x_0) < 0$, then $f$ has a relative maximum at $x_0$,
        \item If $f''(x_0) = 0$, then $f$ is an inflection point.
    \end{itemize}
\end{theorem}

\begin{proof}
    Proving only the first result: if $f''$ is continuous at $x_0$ and $\lim_{c \to x_0} f''(c) = f''(x_0) > 0$. Then, $\exists \delta > 0$ such that $f''(c) > 0, \forall c \in (x_0 - \delta, x_0 + \delta)$. Take $ x \in (x_0 - \delta, x_0 + \delta)$, then, by Taylor's theorem, $\exists c \in (x, x_0)$ and $c \in (x_0 - \delta, x_0 + \delta)$ by consequence, such that:
    \begin{equation*}
        f(x) = f(x_0) + \frac{f''(c)}{2}(x-x_0)^2 \geq f(x_0)
    \end{equation*}
    With $f(x) > f(x_0)$ if $x \neq x_0$.
\end{proof}